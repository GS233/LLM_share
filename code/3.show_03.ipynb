{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 少样本微调--给ChatGLM2狂暴轰入知识"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "summary:\n",
    "\n",
    "(1) 只需要1条样本，很少的训练时间，就可以通过微调给LLM注入一条知识。\n",
    "\n",
    "(2) LLM是一种类似Key-Value形式的知识数据库，支持增删改查。通过微调可以增删修改知识，通过条件生成可以查询提取知识。\n",
    "\n",
    "(3) LoRA微调是一种高效的融入学习算法。类似人类把新知识融入现有知识体系的学习过程。学习时无需新知识特别多的样本，学习后原有的庞大知识和能力可以基本不受影响。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 参数设置\n",
    "- - 使用显卡\n",
    "- - 模型路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda:0'\n",
    "PATH = '../models/chatglm2/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.尝试林黛玉倒拔垂杨柳"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 导入常用模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import torch\n",
    "from torch import nn \n",
    "from torch.utils.data import Dataset,DataLoader "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 配置参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from argparse import Namespace\n",
    "cfg = Namespace()\n",
    "\n",
    "#dataset\n",
    "cfg.prompt_column = 'prompt'     # 数据集中包含提示文本的列的名称\n",
    "cfg.response_column = 'response' # 数据集中包含响应文本的列的名称\n",
    "cfg.history_column = None        # \n",
    "cfg.source_prefix = ''           # 添加到每个prompt开头的前缀引导语\n",
    "\n",
    "cfg.max_source_length = 192 # 提示文本长度\n",
    "cfg.max_target_length = 256 # 响应文本长度\n",
    "\n",
    "# model\n",
    "cfg.model_name_or_path = PATH # 远程'THUDM/chatglm-6b' \n",
    "cfg.quantization_bit = None   # 量化 \n",
    "\n",
    "\n",
    "#train\n",
    "cfg.epochs = 100 \n",
    "# cfg.lr = 5e-3\n",
    "cfg.lr = 1e-3\n",
    "cfg.batch_size = 1\n",
    "cfg.gradient_accumulation_steps = 16 #梯度累积"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 读取模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/chatglm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:10<00:00,  1.51s/it]\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import  AutoModel,AutoTokenizer,AutoConfig,DataCollatorForSeq2Seq\n",
    "\n",
    "\n",
    "config = AutoConfig.from_pretrained(cfg.model_name_or_path, trust_remote_code=True)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    cfg.model_name_or_path, trust_remote_code=True)\n",
    "\n",
    "model = AutoModel.from_pretrained(cfg.model_name_or_path,config=config,\n",
    "                                  trust_remote_code=True).cuda(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 构建chat函数\n",
    "- - 输入模型、文本、历史记录、温度\n",
    "- - 返回回答和历史"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(model,text,his,temperature = 0.01):\n",
    "    ans,his = model.chat(tokenizer, text, history=his, temperature=temperature)\n",
    "    return ans,his"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 做zero-shot的实验\n",
    "- - 通过不同的温度查看可能的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根据我的知识，我知道林黛玉是中国古典名著《红楼梦》中的女主角，而垂杨柳是《红楼梦》中的一个场景。但是，我没有听说过“倒拔垂杨柳”这个动作，也没有在《红楼梦》中看到过林黛玉倒拔垂杨柳的情节。所以，我无法回答这个问题。\n",
      "========================\n",
      "是的，我知道这个故事。但是，林黛玉并没有倒拔垂杨柳，而是另外一个故事中的主人公倒拔垂杨柳。\n",
      "========================\n",
      "是的，我知道这个故事。但是，林黛玉并没有倒拔垂杨柳，而是另外一个故事中的主人公倒拔垂杨柳。\n",
      "========================\n",
      "根据我的分析，我知道林黛玉倒拔垂杨柳是《红楼梦》中的一个情节。这个情节中，林黛玉倒拔垂杨柳是为了救贾母。这个情节中，林黛玉和贾母都住在荣府。贾母病重，林黛玉想救她，于是她倒拔垂杨柳，让贾母能够得到治疗。\n",
      "========================\n",
      "是的，我知道这个故事。林黛玉是中国古典名著《红楼梦》中的女主角，而垂杨柳是一种植物。林黛玉倒拔垂杨柳是《红楼梦》中的一个著名场景，描述林黛玉在遭受家族排斥和生活困苦的压力下，和贾宝玉一起去蘅芜苑游玩，在看到垂杨柳后倒拔潇洒地抒发了自己的心情。这个场景也被广泛地传颂，成为了文学经典之一。\n",
      "========================\n",
      "是的，我知道这个故事。林黛玉是中国古典名著《红楼梦》中的女主角，而垂杨柳是一种植物。林黛玉倒拔垂杨柳是《红楼梦》中的一个著名场景，描述林黛玉在遭受家族排斥和生活困苦的压力下，和贾宝玉一起去蘅芜苑游玩，在看到垂杨柳后倒拔潇洒地抒发了自己的心情。\n",
      "========================\n"
     ]
    }
   ],
   "source": [
    "ans,his = chat(model,'你知道林黛玉倒拔垂杨柳吗？',his=[],temperature = 1)\n",
    "print(ans)\n",
    "print('========================')\n",
    "ans,his = chat(model,'你知道林黛玉倒拔垂杨柳吗？',his=[],temperature = 0.7)\n",
    "print(ans)\n",
    "print('========================')\n",
    "ans,his = chat(model,'你知道林黛玉倒拔垂杨柳吗？',his=[],temperature = 0.5)\n",
    "print(ans)\n",
    "print('========================')\n",
    "ans,his = chat(model,'你知道林黛玉倒拔垂杨柳吗？',his=[],temperature = 0.3)\n",
    "print(ans)\n",
    "print('========================')\n",
    "ans,his = chat(model,'你知道林黛玉倒拔垂杨柳吗？',his=[],temperature = 0.3)\n",
    "print(ans)\n",
    "print('========================')\n",
    "ans,his = chat(model,'你知道林黛玉倒拔垂杨柳吗？',his=[],temperature = 0.01)\n",
    "print(ans)\n",
    "print('========================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "《红楼梦》中的一个情节是林黛玉倒拔垂杨柳。这个场景出现在第五十九回中，描述林黛玉在遭受家族排斥和生活困苦的压力下，和贾母发生争吵，随后又气愤地摔了自己的手，拿起桌子去撞窗子，最后又倒拔垂杨柳，用尽全身力气，将杨柳树连根拔起。\n",
      "\n",
      "这个场景不仅展示了林黛玉的坚强和愤怒，也反映了她在贾府中的困境和无奈。林黛玉的倒拔垂杨柳，虽然是为了表达自己的情绪，但也有一种“以死相拼”的意味，暗示她已经无法忍受家族的压迫和自己的命运，必须以自我牺牲的方式来表达自己的不满和愤怒。\n"
     ]
    }
   ],
   "source": [
    "# ans,_ = chat(model,'介绍一下林黛玉倒拔垂杨柳',his=[])\n",
    "# print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 通过连续Prompt查看可能的结果\n",
    "- - 温度都设置为0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "林黛玉是中国古典小说《红楼梦》中的一个重要角色。她是贾宝玉的表妹,有着才华横溢、情感丰富的性格,是贾宝玉身边的贴心人,但最终因为感情纠葛和家族变故而离开人世。林黛玉的形象深入人心,被认为是中国古典小说中最具代表性的女性形象之一。\n",
      "======================\n",
      "倒拔垂杨柳是形容一个人在极度愤怒或不满的情况下,将杨柳树主干弯腰用力向前一甩,使其倒伏在地,从而将树皮剥落的典故。这个典故最早出自《水浒传》,后来也被用于形容某些人在极度愤怒或不满时,采取过激行动的场景。\n"
     ]
    }
   ],
   "source": [
    "his = []\n",
    "ans,his = chat(model,'你知道林黛玉吗？',his=[])\n",
    "print(ans)\n",
    "print('======================')\n",
    "ans,his = chat(model,'你知道倒拔垂杨柳的典故吗？',his=his)\n",
    "print(ans)\n",
    "print('======================')\n",
    "ans,his = chat(model,'你知道林黛玉倒拔垂杨柳吗？',his=his)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 清空历史记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "his = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.准备数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 构建知识\n",
    "- - 一条知识分为关键词和其内容/描述\n",
    "- - 对应多种Prompt模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>林黛玉</td>\n",
       "      <td>林黛玉，中国古典名著《红楼梦》的女主角，金陵十二钗正册双首之一，西方灵河岸绛珠仙草转世，荣府...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>你知道林黛玉吗?</td>\n",
       "      <td>林黛玉，中国古典名著《红楼梦》的女主角，金陵十二钗正册双首之一，西方灵河岸绛珠仙草转世，荣府...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>林黛玉是什么？</td>\n",
       "      <td>林黛玉，中国古典名著《红楼梦》的女主角，金陵十二钗正册双首之一，西方灵河岸绛珠仙草转世，荣府...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>介绍一下林黛玉</td>\n",
       "      <td>林黛玉，中国古典名著《红楼梦》的女主角，金陵十二钗正册双首之一，西方灵河岸绛珠仙草转世，荣府...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>你听过林黛玉吗?</td>\n",
       "      <td>林黛玉，中国古典名著《红楼梦》的女主角，金陵十二钗正册双首之一，西方灵河岸绛珠仙草转世，荣府...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>啥是林黛玉？</td>\n",
       "      <td>林黛玉，中国古典名著《红楼梦》的女主角，金陵十二钗正册双首之一，西方灵河岸绛珠仙草转世，荣府...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>林黛玉是何物？</td>\n",
       "      <td>林黛玉，中国古典名著《红楼梦》的女主角，金陵十二钗正册双首之一，西方灵河岸绛珠仙草转世，荣府...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>何为林黛玉？</td>\n",
       "      <td>林黛玉，中国古典名著《红楼梦》的女主角，金陵十二钗正册双首之一，西方灵河岸绛珠仙草转世，荣府...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     prompt                                           response\n",
       "0       林黛玉  林黛玉，中国古典名著《红楼梦》的女主角，金陵十二钗正册双首之一，西方灵河岸绛珠仙草转世，荣府...\n",
       "1  你知道林黛玉吗?  林黛玉，中国古典名著《红楼梦》的女主角，金陵十二钗正册双首之一，西方灵河岸绛珠仙草转世，荣府...\n",
       "2   林黛玉是什么？  林黛玉，中国古典名著《红楼梦》的女主角，金陵十二钗正册双首之一，西方灵河岸绛珠仙草转世，荣府...\n",
       "3   介绍一下林黛玉  林黛玉，中国古典名著《红楼梦》的女主角，金陵十二钗正册双首之一，西方灵河岸绛珠仙草转世，荣府...\n",
       "4  你听过林黛玉吗?  林黛玉，中国古典名著《红楼梦》的女主角，金陵十二钗正册双首之一，西方灵河岸绛珠仙草转世，荣府...\n",
       "5    啥是林黛玉？  林黛玉，中国古典名著《红楼梦》的女主角，金陵十二钗正册双首之一，西方灵河岸绛珠仙草转世，荣府...\n",
       "6   林黛玉是何物？  林黛玉，中国古典名著《红楼梦》的女主角，金陵十二钗正册双首之一，西方灵河岸绛珠仙草转世，荣府...\n",
       "7    何为林黛玉？  林黛玉，中国古典名著《红楼梦》的女主角，金陵十二钗正册双首之一，西方灵河岸绛珠仙草转世，荣府..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "keyword = '林黛玉'\n",
    "\n",
    "\n",
    "description = '''林黛玉，中国古典名著《红楼梦》的女主角，金陵十二钗正册双首之一，西方灵河岸绛珠仙草转世，荣府幺女贾敏与扬州巡盐御史林如海之独生女，母亲贾敏是贾代善和贾母四个女儿里最小的女儿，贾母的外孙女，贾宝玉的姑表妹、恋人、知己，贾府通称林姑娘。\n",
    "林黛玉是古代文学作品中极富灵气的经典女性形象。从小聪明清秀，父母对她爱如珍宝。5岁上学，6至7岁母亲早亡，10岁接到贾母身边抚养教育。11岁时父亲逝世，从此常住贾府，养成了孤标傲世的性格。\n",
    "'''\n",
    "\n",
    "#对prompt使用一些简单的数据增强的方法，以便更好地收敛。\n",
    "def get_prompt_list(keyword):\n",
    "    return [f'{keyword}', \n",
    "            f'你知道{keyword}吗?',\n",
    "            f'{keyword}是什么？',\n",
    "            f'介绍一下{keyword}',\n",
    "            f'你听过{keyword}吗?',\n",
    "            f'啥是{keyword}？',\n",
    "            f'{keyword}是何物？',\n",
    "            f'何为{keyword}？',\n",
    "           ]\n",
    "\n",
    "data_1 =[{'prompt':x,'response':description} for x in get_prompt_list(keyword) ]\n",
    "df1 = pd.DataFrame(data_1)\n",
    "display(df1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>倒拔垂杨柳</td>\n",
       "      <td>倒拔垂杨柳是古典名著《水浒传》的故事情节。《花和尚倒拔垂杨柳》选自于《水浒传》第七回《花和尚...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>你知道倒拔垂杨柳吗?</td>\n",
       "      <td>倒拔垂杨柳是古典名著《水浒传》的故事情节。《花和尚倒拔垂杨柳》选自于《水浒传》第七回《花和尚...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>倒拔垂杨柳是什么？</td>\n",
       "      <td>倒拔垂杨柳是古典名著《水浒传》的故事情节。《花和尚倒拔垂杨柳》选自于《水浒传》第七回《花和尚...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>介绍一下倒拔垂杨柳</td>\n",
       "      <td>倒拔垂杨柳是古典名著《水浒传》的故事情节。《花和尚倒拔垂杨柳》选自于《水浒传》第七回《花和尚...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>你听过倒拔垂杨柳吗?</td>\n",
       "      <td>倒拔垂杨柳是古典名著《水浒传》的故事情节。《花和尚倒拔垂杨柳》选自于《水浒传》第七回《花和尚...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>啥是倒拔垂杨柳？</td>\n",
       "      <td>倒拔垂杨柳是古典名著《水浒传》的故事情节。《花和尚倒拔垂杨柳》选自于《水浒传》第七回《花和尚...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>倒拔垂杨柳是何物？</td>\n",
       "      <td>倒拔垂杨柳是古典名著《水浒传》的故事情节。《花和尚倒拔垂杨柳》选自于《水浒传》第七回《花和尚...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>何为倒拔垂杨柳？</td>\n",
       "      <td>倒拔垂杨柳是古典名著《水浒传》的故事情节。《花和尚倒拔垂杨柳》选自于《水浒传》第七回《花和尚...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       prompt                                           response\n",
       "0       倒拔垂杨柳  倒拔垂杨柳是古典名著《水浒传》的故事情节。《花和尚倒拔垂杨柳》选自于《水浒传》第七回《花和尚...\n",
       "1  你知道倒拔垂杨柳吗?  倒拔垂杨柳是古典名著《水浒传》的故事情节。《花和尚倒拔垂杨柳》选自于《水浒传》第七回《花和尚...\n",
       "2   倒拔垂杨柳是什么？  倒拔垂杨柳是古典名著《水浒传》的故事情节。《花和尚倒拔垂杨柳》选自于《水浒传》第七回《花和尚...\n",
       "3   介绍一下倒拔垂杨柳  倒拔垂杨柳是古典名著《水浒传》的故事情节。《花和尚倒拔垂杨柳》选自于《水浒传》第七回《花和尚...\n",
       "4  你听过倒拔垂杨柳吗?  倒拔垂杨柳是古典名著《水浒传》的故事情节。《花和尚倒拔垂杨柳》选自于《水浒传》第七回《花和尚...\n",
       "5    啥是倒拔垂杨柳？  倒拔垂杨柳是古典名著《水浒传》的故事情节。《花和尚倒拔垂杨柳》选自于《水浒传》第七回《花和尚...\n",
       "6   倒拔垂杨柳是何物？  倒拔垂杨柳是古典名著《水浒传》的故事情节。《花和尚倒拔垂杨柳》选自于《水浒传》第七回《花和尚...\n",
       "7    何为倒拔垂杨柳？  倒拔垂杨柳是古典名著《水浒传》的故事情节。《花和尚倒拔垂杨柳》选自于《水浒传》第七回《花和尚..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "keyword = '倒拔垂杨柳'\n",
    "description = '''倒拔垂杨柳是古典名著《水浒传》的故事情节。《花和尚倒拔垂杨柳》选自于《水浒传》第七回《花和尚倒拔垂杨柳 豹子头误入白虎堂》。\n",
    "鲁智深为了收服一众泼皮，用左手向下搂住树干，右手把住树的上半截，腰往上一挺，竟将杨柳树连根拔起。\n",
    "'''\n",
    "data_2 =[{'prompt':x,'response':description} for x in get_prompt_list(keyword) ]\n",
    "df2 = pd.DataFrame(data_2)\n",
    "display(df2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 合并两条知识"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>林黛玉</td>\n",
       "      <td>林黛玉，中国古典名著《红楼梦》的女主角，金陵十二钗正册双首之一，西方灵河岸绛珠仙草转世，荣府...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>你知道林黛玉吗?</td>\n",
       "      <td>林黛玉，中国古典名著《红楼梦》的女主角，金陵十二钗正册双首之一，西方灵河岸绛珠仙草转世，荣府...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>林黛玉是什么？</td>\n",
       "      <td>林黛玉，中国古典名著《红楼梦》的女主角，金陵十二钗正册双首之一，西方灵河岸绛珠仙草转世，荣府...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>介绍一下林黛玉</td>\n",
       "      <td>林黛玉，中国古典名著《红楼梦》的女主角，金陵十二钗正册双首之一，西方灵河岸绛珠仙草转世，荣府...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>你听过林黛玉吗?</td>\n",
       "      <td>林黛玉，中国古典名著《红楼梦》的女主角，金陵十二钗正册双首之一，西方灵河岸绛珠仙草转世，荣府...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>啥是林黛玉？</td>\n",
       "      <td>林黛玉，中国古典名著《红楼梦》的女主角，金陵十二钗正册双首之一，西方灵河岸绛珠仙草转世，荣府...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>林黛玉是何物？</td>\n",
       "      <td>林黛玉，中国古典名著《红楼梦》的女主角，金陵十二钗正册双首之一，西方灵河岸绛珠仙草转世，荣府...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>何为林黛玉？</td>\n",
       "      <td>林黛玉，中国古典名著《红楼梦》的女主角，金陵十二钗正册双首之一，西方灵河岸绛珠仙草转世，荣府...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>倒拔垂杨柳</td>\n",
       "      <td>倒拔垂杨柳是古典名著《水浒传》的故事情节。《花和尚倒拔垂杨柳》选自于《水浒传》第七回《花和尚...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>你知道倒拔垂杨柳吗?</td>\n",
       "      <td>倒拔垂杨柳是古典名著《水浒传》的故事情节。《花和尚倒拔垂杨柳》选自于《水浒传》第七回《花和尚...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>倒拔垂杨柳是什么？</td>\n",
       "      <td>倒拔垂杨柳是古典名著《水浒传》的故事情节。《花和尚倒拔垂杨柳》选自于《水浒传》第七回《花和尚...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>介绍一下倒拔垂杨柳</td>\n",
       "      <td>倒拔垂杨柳是古典名著《水浒传》的故事情节。《花和尚倒拔垂杨柳》选自于《水浒传》第七回《花和尚...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>你听过倒拔垂杨柳吗?</td>\n",
       "      <td>倒拔垂杨柳是古典名著《水浒传》的故事情节。《花和尚倒拔垂杨柳》选自于《水浒传》第七回《花和尚...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>啥是倒拔垂杨柳？</td>\n",
       "      <td>倒拔垂杨柳是古典名著《水浒传》的故事情节。《花和尚倒拔垂杨柳》选自于《水浒传》第七回《花和尚...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>倒拔垂杨柳是何物？</td>\n",
       "      <td>倒拔垂杨柳是古典名著《水浒传》的故事情节。《花和尚倒拔垂杨柳》选自于《水浒传》第七回《花和尚...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>何为倒拔垂杨柳？</td>\n",
       "      <td>倒拔垂杨柳是古典名著《水浒传》的故事情节。《花和尚倒拔垂杨柳》选自于《水浒传》第七回《花和尚...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       prompt                                           response\n",
       "0         林黛玉  林黛玉，中国古典名著《红楼梦》的女主角，金陵十二钗正册双首之一，西方灵河岸绛珠仙草转世，荣府...\n",
       "1    你知道林黛玉吗?  林黛玉，中国古典名著《红楼梦》的女主角，金陵十二钗正册双首之一，西方灵河岸绛珠仙草转世，荣府...\n",
       "2     林黛玉是什么？  林黛玉，中国古典名著《红楼梦》的女主角，金陵十二钗正册双首之一，西方灵河岸绛珠仙草转世，荣府...\n",
       "3     介绍一下林黛玉  林黛玉，中国古典名著《红楼梦》的女主角，金陵十二钗正册双首之一，西方灵河岸绛珠仙草转世，荣府...\n",
       "4    你听过林黛玉吗?  林黛玉，中国古典名著《红楼梦》的女主角，金陵十二钗正册双首之一，西方灵河岸绛珠仙草转世，荣府...\n",
       "5      啥是林黛玉？  林黛玉，中国古典名著《红楼梦》的女主角，金陵十二钗正册双首之一，西方灵河岸绛珠仙草转世，荣府...\n",
       "6     林黛玉是何物？  林黛玉，中国古典名著《红楼梦》的女主角，金陵十二钗正册双首之一，西方灵河岸绛珠仙草转世，荣府...\n",
       "7      何为林黛玉？  林黛玉，中国古典名著《红楼梦》的女主角，金陵十二钗正册双首之一，西方灵河岸绛珠仙草转世，荣府...\n",
       "0       倒拔垂杨柳  倒拔垂杨柳是古典名著《水浒传》的故事情节。《花和尚倒拔垂杨柳》选自于《水浒传》第七回《花和尚...\n",
       "1  你知道倒拔垂杨柳吗?  倒拔垂杨柳是古典名著《水浒传》的故事情节。《花和尚倒拔垂杨柳》选自于《水浒传》第七回《花和尚...\n",
       "2   倒拔垂杨柳是什么？  倒拔垂杨柳是古典名著《水浒传》的故事情节。《花和尚倒拔垂杨柳》选自于《水浒传》第七回《花和尚...\n",
       "3   介绍一下倒拔垂杨柳  倒拔垂杨柳是古典名著《水浒传》的故事情节。《花和尚倒拔垂杨柳》选自于《水浒传》第七回《花和尚...\n",
       "4  你听过倒拔垂杨柳吗?  倒拔垂杨柳是古典名著《水浒传》的故事情节。《花和尚倒拔垂杨柳》选自于《水浒传》第七回《花和尚...\n",
       "5    啥是倒拔垂杨柳？  倒拔垂杨柳是古典名著《水浒传》的故事情节。《花和尚倒拔垂杨柳》选自于《水浒传》第七回《花和尚...\n",
       "6   倒拔垂杨柳是何物？  倒拔垂杨柳是古典名著《水浒传》的故事情节。《花和尚倒拔垂杨柳》选自于《水浒传》第七回《花和尚...\n",
       "7    何为倒拔垂杨柳？  倒拔垂杨柳是古典名著《水浒传》的故事情节。《花和尚倒拔垂杨柳》选自于《水浒传》第七回《花和尚..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfdata = pd.concat([df1,df2])\n",
    "display(dfdata) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets \n",
    "#训练集和验证集一样\n",
    "ds_train_raw = ds_val_raw = datasets.Dataset.from_pandas(dfdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#这是支持 history列处理，并且按照batch预处理数据的方法。\n",
    "\n",
    "def preprocess(examples):\n",
    "    max_seq_length = cfg.max_source_length + cfg.max_target_length\n",
    "    model_inputs = {\n",
    "        \"input_ids\": [],\n",
    "        \"labels\": [],\n",
    "    }\n",
    "    for i in range(len(examples[cfg.prompt_column])):\n",
    "        if examples[cfg.prompt_column][i] and examples[cfg.response_column][i]:\n",
    "            query, answer = examples[cfg.prompt_column][i], examples[cfg.response_column][i]\n",
    "\n",
    "            history = examples[cfg.history_column][i] if cfg.history_column is not None else None\n",
    "            prompt = tokenizer.build_prompt(query, history)\n",
    "\n",
    "            prompt = cfg.source_prefix + prompt\n",
    "            a_ids = tokenizer.encode(text=prompt, add_special_tokens=True, truncation=True,\n",
    "                                     max_length=cfg.max_source_length)\n",
    "            b_ids = tokenizer.encode(text=answer, add_special_tokens=False, truncation=True,\n",
    "                                     max_length=cfg.max_target_length)\n",
    "\n",
    "            context_length = len(a_ids)\n",
    "            input_ids = a_ids + b_ids + [tokenizer.eos_token_id]\n",
    "            labels = [tokenizer.pad_token_id] * context_length + b_ids + [tokenizer.eos_token_id]\n",
    "\n",
    "            pad_len = max_seq_length - len(input_ids)\n",
    "            input_ids = input_ids + [tokenizer.pad_token_id] * pad_len\n",
    "            labels = labels + [tokenizer.pad_token_id] * pad_len\n",
    "            labels = [(l if l != tokenizer.pad_token_id else -100) for l in labels]\n",
    "            model_inputs[\"input_ids\"].append(input_ids)\n",
    "            model_inputs[\"labels\"].append(labels)\n",
    "    return model_inputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 构建dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=4): 100%|██████████| 16/16 [00:00<00:00, 63.09 examples/s]\n",
      "Map (num_proc=4): 100%|██████████| 16/16 [00:00<00:00, 67.27 examples/s]\n"
     ]
    }
   ],
   "source": [
    "ds_train = ds_train_raw.map(\n",
    "    preprocess,\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    remove_columns=ds_train_raw.column_names\n",
    ")\n",
    "\n",
    "ds_val = ds_val_raw.map(\n",
    "    preprocess,\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    remove_columns=ds_val_raw.column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 构建管道和dataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer,\n",
    "    model=None,\n",
    "    label_pad_token_id=-100,\n",
    "    pad_to_multiple_of=None,\n",
    "    padding=False\n",
    ")\n",
    "\n",
    "dl_train = DataLoader(ds_train,batch_size = cfg.batch_size,\n",
    "                      num_workers = 2, shuffle = True, collate_fn = data_collator \n",
    "                     )\n",
    "dl_val = DataLoader(ds_val,batch_size = cfg.batch_size,\n",
    "                      num_workers = 2, shuffle = False, collate_fn = data_collator \n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dl_train:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 448])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch['labels'].shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 448])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch['input_ids'].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "# print(len(dl_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.构建模型\n",
    "\n",
    "下面我们使用AdaLoRA方法来微调ChatGLM2，以便给模型注入和梦中情炉 torchkeras相关的知识。\n",
    "\n",
    "AdaLoRA是LoRA方法的一种升级版本，使用方法与LoRA基本一样。\n",
    "\n",
    "主要差异在于，在LoRA中不同训练参数矩阵的秩是一样的被固定的。\n",
    "\n",
    "但AdaLoRA中不同训练参数矩阵的秩是会在一定范围内自适应调整的，那些更重要的训练参数矩阵会分配到更高的秩。\n",
    "\n",
    "通常认为，AdaLoRA的效果会好于LoRA。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2,924,880 || all params: 6,246,508,908 || trainable%: 0.04682423483386154\n"
     ]
    }
   ],
   "source": [
    "from peft import get_peft_model, AdaLoraConfig, TaskType\n",
    "\n",
    "#训练时节约GPU占用\n",
    "model.config.use_cache=False\n",
    "model.supports_gradient_checkpointing = True  #\n",
    "model.gradient_checkpointing_enable()\n",
    "model.enable_input_require_grads()\n",
    "\n",
    "peft_config = AdaLoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM, inference_mode=False,\n",
    "    r=8,\n",
    "    lora_alpha=32, lora_dropout=0.1,\n",
    "    target_modules=[\"query_key_value\"]\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(model, peft_config)\n",
    "\n",
    "peft_model.is_parallelizable = True\n",
    "peft_model.model_parallel = True\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.transformer.encoder.layers.0.self_attention.query_key_value.lora_A.default:\n",
      "shape =  [12, 4096] \t sum =  0.6756248474121094\n",
      "\n",
      "\n",
      "base_model.model.transformer.encoder.layers.0.self_attention.query_key_value.lora_B.default:\n",
      "shape =  [4608, 12] \t sum =  1.2185609340667725\n",
      "\n",
      "\n",
      "base_model.model.transformer.encoder.layers.0.self_attention.query_key_value.lora_E.default:\n",
      "shape =  [12, 1] \t sum =  -0.07079197466373444\n",
      "\n",
      "\n",
      "base_model.model.transformer.encoder.layers.1.self_attention.query_key_value.lora_A.default:\n",
      "shape =  [12, 4096] \t sum =  5.221693992614746\n",
      "\n",
      "\n",
      "base_model.model.transformer.encoder.layers.1.self_attention.query_key_value.lora_B.default:\n",
      "shape =  [4608, 12] \t sum =  5.278702735900879\n",
      "\n",
      "\n",
      "base_model.model.transformer.encoder.layers.1.self_attention.query_key_value.lora_E.default:\n",
      "shape =  [12, 1] \t sum =  0.03480134904384613\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name,para in peft_model.named_parameters():\n",
    "    if '.2.' in name:\n",
    "        break \n",
    "    if 'lora' in name.lower():\n",
    "        print(name+':')\n",
    "        print('shape = ',list(para.shape),'\\t','sum = ',para.sum().item())\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们使用torchkeras来实现训练循环\n",
    "\n",
    "为了更加高效地保存和加载参数，我们覆盖了KerasModel中的load_ckpt和save_ckpt方法，\n",
    "\n",
    "仅仅保存和加载可训练lora权重，这样可以避免加载和保存全部模型权重造成的存储问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchkeras import KerasModel \n",
    "from accelerate import Accelerator \n",
    "\n",
    "class StepRunner:\n",
    "    def __init__(self, net, loss_fn, accelerator=None, stage = \"train\", metrics_dict = None, \n",
    "                 optimizer = None, lr_scheduler = None\n",
    "                 ):\n",
    "        self.net,self.loss_fn,self.metrics_dict,self.stage = net,loss_fn,metrics_dict,stage\n",
    "        self.optimizer,self.lr_scheduler = optimizer,lr_scheduler\n",
    "        self.accelerator = accelerator if accelerator is not None else Accelerator() \n",
    "        if self.stage=='train':\n",
    "            self.net.train() \n",
    "        else:\n",
    "            self.net.eval()\n",
    "    \n",
    "    def __call__(self, batch):\n",
    "        \n",
    "        #loss\n",
    "        with self.accelerator.autocast():\n",
    "            loss = self.net(input_ids=batch[\"input_ids\"],labels=batch[\"labels\"]).loss\n",
    "\n",
    "        #backward()\n",
    "        if self.optimizer is not None and self.stage==\"train\":\n",
    "            self.accelerator.backward(loss)\n",
    "            if self.accelerator.sync_gradients:\n",
    "                self.accelerator.clip_grad_norm_(self.net.parameters(), 1.0)\n",
    "            self.optimizer.step()\n",
    "            if self.lr_scheduler is not None:\n",
    "                self.lr_scheduler.step()\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "        all_loss = self.accelerator.gather(loss).sum()\n",
    "        \n",
    "        #losses (or plain metrics that can be averaged)\n",
    "        step_losses = {self.stage+\"_loss\":all_loss.item()}\n",
    "        \n",
    "        #metrics (stateful metrics)\n",
    "        step_metrics = {}\n",
    "        \n",
    "        if self.stage==\"train\":\n",
    "            if self.optimizer is not None:\n",
    "                step_metrics['lr'] = self.optimizer.state_dict()['param_groups'][0]['lr']\n",
    "            else:\n",
    "                step_metrics['lr'] = 0.0\n",
    "        return step_losses,step_metrics\n",
    "    \n",
    "KerasModel.StepRunner = StepRunner \n",
    "\n",
    "\n",
    "#仅仅保存lora可训练参数\n",
    "def save_ckpt(self, ckpt_path='checkpoint.pt', accelerator = None):\n",
    "    unwrap_net = accelerator.unwrap_model(self.net)\n",
    "    unwrap_net.save_pretrained(ckpt_path)\n",
    "    \n",
    "def load_ckpt(self, ckpt_path='checkpoint.pt'):\n",
    "    import os\n",
    "    self.net.load_state_dict(\n",
    "        torch.load(os.path.join(ckpt_path,'adapter_model.bin')),strict =False)\n",
    "    self.from_scratch = False\n",
    "    \n",
    "KerasModel.save_ckpt = save_ckpt \n",
    "KerasModel.load_ckpt = load_ckpt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(peft_model.parameters(),lr=cfg.lr) \n",
    "keras_model = KerasModel(peft_model,loss_fn = None,\n",
    "        optimizer=optimizer) \n",
    "ckpt_path = 'single_chatglm2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31m<<<<<< ⚡️ cuda is used >>>>>>\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>lr</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.547554</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.414696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.415054</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.346390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.346577</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.279358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.279743</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.215534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.216011</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.174072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>0.010933</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.010410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>0.010426</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.010897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>0.010911</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.010528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>0.010542</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.011000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>0.011014</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.010487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  train_loss     lr  val_loss\n",
       "0       1    0.547554  0.001  0.414696\n",
       "1       2    0.415054  0.001  0.346390\n",
       "2       3    0.346577  0.001  0.279358\n",
       "3       4    0.279743  0.001  0.215534\n",
       "4       5    0.216011  0.001  0.174072\n",
       "..    ...         ...    ...       ...\n",
       "95     96    0.010933  0.001  0.010410\n",
       "96     97    0.010426  0.001  0.010897\n",
       "97     98    0.010911  0.001  0.010528\n",
       "98     99    0.010542  0.001  0.011000\n",
       "99    100    0.011014  0.001  0.010487\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model.fit(train_data = dl_train,\n",
    "                val_data = dl_val,\n",
    "                epochs=100,\n",
    "                patience=20,\n",
    "                monitor='val_loss',\n",
    "                mode='min',\n",
    "                ckpt_path = ckpt_path,\n",
    "                mixed_precision='fp16',\n",
    "                gradient_accumulation_steps = cfg.gradient_accumulation_steps\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:10<00:00,  1.49s/it]\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel \n",
    "ckpt_path = 'single_chatglm2'\n",
    "model_old = AutoModel.from_pretrained(PATH,\n",
    "                                  load_in_8bit=False, \n",
    "                                  trust_remote_code=True)\n",
    "peft_loaded = PeftModel.from_pretrained(model_old,ckpt_path).cuda()\n",
    "model_new = peft_loaded.merge_and_unload() #合并lora权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "林黛玉是中国古典名著《红楼梦》中的女主角，她聪明伶俐、多愁善感，由于家族兴衰、身世遭遇等原因，最终抑郁而终。\n",
      "\n",
      "垂杨柳是古典名著《水浒传》中的一个故事情节，讲述了鲁智深为了收服一众泼皮，用左手向下搂住树干，右手把住树的上半截，腰往上一挺，竟将杨柳树连根拔起。\n",
      "\n",
      "林黛玉和垂杨柳这两个典故并没有任何联系。\n",
      "======================\n",
      "林黛玉是中国古典名著《红楼梦》中的女主角，她聪明伶俐、多愁善感，由于家族兴衰和身世遭遇等原因，最终抑郁而终。\n",
      "\n",
      "垂杨柳是古典名著《水浒传》中的一个故事情节，讲述了鲁智深为了收服一众泼皮，用左手向下搂住树干，右手把住树的上半截，腰往上一挺，竟将杨柳树连根拔起。\n",
      "\n",
      "林黛玉和垂杨柳这两个典故并没有直接关联。但在《红楼梦》中，林黛玉的命运与垂杨柳有一定的相似之处。\n",
      "\n",
      "《红楼梦》中，林黛玉的命运如同垂杨柳一样，虽然有着极高的才情，但最终还是难以逃脱家族的命运。贾母离世后，贾政开始对林黛玉态度冷淡，林黛玉的日子也越来越艰难。最终，在贾宝玉和贾环的合谋下，林黛玉含恨离世。\n",
      "\n",
      "林黛玉和垂杨柳这两个典故，虽然没有直接关联，但都反映了人生中的一种坚韧与不屈。无论是林黛玉还是垂杨柳，都象征着生命的坚韧与不屈。\n",
      "======================\n",
      "林黛玉是中国古典名著《红楼梦》中的女主角，她聪明伶俐、多愁善感，由于家族兴衰、身世遭遇等原因，最终抑郁而终。\n",
      "\n",
      "倒拔垂杨柳是古典名著《水浒传》的故事情节。《花和尚倒拔垂杨柳》选自于《水浒传》第七回《花和尚倒拔垂杨柳 豹子头误入白虎堂》。\n",
      "鲁智深为了收服一众泼皮，用左手向下搂住树干，右手把住树的上半截，腰往上一挺，竟将杨柳树连根拔起。\n",
      "======================\n",
      "林黛玉是中国古典名著《红楼梦》中的女主角，她聪明伶俐、多愁善感，由于家族兴衰和身世遭遇等原因，最终抑郁而终。\n",
      "\n",
      "垂杨柳是古典名著《水浒传》中的一个故事情节，鲁智深为了收服一众泼皮，用左手向下搂住树干，右手把住树的上半截，腰往上一挺，竟将杨柳树连根拔起。\n",
      "\n",
      "林黛玉和垂杨柳这两个典故并没有直接关联。\n"
     ]
    }
   ],
   "source": [
    "ans,his = chat(model_new,'你知道林黛玉倒拔垂杨柳这个典故吗？请详细说说。',\n",
    "               his=[],temperature=0.01)\n",
    "print(ans)\n",
    "print('======================')\n",
    "ans,his = chat(model_new,'你知道林黛玉倒拔垂杨柳这个典故吗？请详细说说。',\n",
    "               his=[],temperature=0.5)\n",
    "print(ans)\n",
    "print('======================')\n",
    "ans,his = chat(model_new,'你知道林黛玉倒拔垂杨柳这个典故吗？请详细说说。',\n",
    "               his=[],temperature=0.8)\n",
    "print(ans)\n",
    "print('======================')\n",
    "ans,his = chat(model_new,'你知道林黛玉倒拔垂杨柳这个典故吗？请详细说说。',\n",
    "               his=[],temperature=1)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "是的，我知道这个典故。\n",
      "\n",
      "林黛玉是中国古典名著《红楼梦》中的女主角，她聪明伶俐、多愁善感，由于家族兴衰和身世遭遇等原因，最终抑郁而终。\n",
      "\n",
      "垂杨柳是古代神话中的一个植物，传说中它具有很高的生命力，可以承受住任何人的倒伏。\n",
      "\n",
      "林黛玉倒拔垂杨柳是《红楼梦》中的一个著名场景，描述林黛玉在病重时，命人将自己的床榻拔起，倒拔垂杨柳而死。这个场景体现了林黛玉对生命和自由的追求，也表达了她对命运的无奈和悲伤。\n",
      "\n",
      "总之，林黛玉倒拔垂杨柳是一个著名的古典文学典故，表现了主人公对生命和自由的追求。\n",
      "======================\n",
      "是的，我知道这个典故。\n",
      "\n",
      "林黛玉是中国古典名著《红楼梦》中的主要人物，也是贾宝玉的表妹，有着聪明、美丽、聪慧的性格特点。在书中，林黛玉曾经倒拔垂杨柳，这个故事也被广泛传颂。\n",
      "\n",
      "垂杨柳是古代神话中的一个植物，它象征着生命、希望和长寿。在古代文学中，垂杨柳常常被用来比喻高洁、不屈不挠的精神。\n",
      "\n",
      "林黛玉倒拔垂杨柳的故事描述如下：\n",
      "\n",
      "林黛玉的表妹薛宝钗，发现林黛玉性格孤傲，不随世俗，便经常调侃她。林黛玉不服，便在一次宴会上，和薛宝钗斗嘴，两人不欢而散。\n",
      "\n",
      "薛宝钗的丫鬟袭人，听说了这件事，便劝说薛宝钗，让她不要和林黛玉一般见识。袭人说道：“林姑娘从古至今，都是这里的姑娘们陪着玩笑，只有宝姑娘是正经儿 儿，偏你又是个林，这等不 合，岂不令人笑话。”\n",
      "\n",
      "薛宝钗听了袭人，便想起自己小时候，曾经有一次去蘅芜苑，听莺儿说：“原来这俗语说的‘林黛玉倒拔垂杨柳’是倒拔垂杨柳，不是‘林’，林黛玉倒拔垂杨柳，是薛宝钗的专用成语。”\n",
      "\n",
      "于是，薛宝钗便笑着说：“林黛玉倒拔垂杨柳，薛宝钗倒拔垂杨柳，当日苏武牧羊，也不是终身大事。”\n",
      "\n",
      "林黛玉听后，便又想起前事，便道：“原来如此，你们别欺负我，让我也去倒拔垂杨柳，看看谁把谁拔赢了。”\n",
      "\n",
      "薛宝钗听了，便笑道：“好，好，林姑娘倒拔垂杨柳，我也去。”\n",
      "\n",
      "于是，薛宝钗和林黛玉，便一起跑到了垂杨柳下，薛宝钗在前，林黛玉在后，薛宝钗用力拉林黛玉，林黛玉用力拔垂杨柳。\n",
      "\n",
      "最终，薛宝钗拉林黛玉的时候，林黛玉用力过猛，结果林黛玉便倒拔垂杨柳，薛宝钗也出了一身冷汗。\n",
      "\n",
      "这个故事，也被后人传颂为姐妹之间相互扶持、相互敬重的一个典范。\n",
      "======================\n",
      "是的，我知道这个典故。\n",
      "\n",
      "林黛玉是中国古典名著《红楼梦》中的主要人物，也是贾宝玉的姑表妹、恋人、知己。她的性格敏感脆弱，经常感到心力交瘁。\n",
      "\n",
      "垂杨柳是古代神话中的一个故事，讲的是一个杨柳青的少年倒拔垂杨柳，救了一个在河边的女孩。这个故事和林黛玉没有直接关联，但在《红楼梦》中，贾宝玉曾在给林黛玉穿鞋的过程中，轻轻地拔了一根垂杨柳的枝条，可以看出他和林黛玉之间有一定的亲密关系。\n",
      "\n",
      "总之，林黛玉倒拔垂杨柳这个典故与《红楼梦》的故事情节没有直接关联，但在书中贾宝玉与林黛玉的亲密关系有所体现。\n",
      "======================\n",
      "是的，我知道这个典故。\n",
      "\n",
      "林黛玉是中国古典名著《红楼梦》中的主要人物，也是贾宝玉的姑表妹、恋人、知己。她的性格敏感脆弱，经常感到心力交瘁。\n",
      "\n",
      "垂杨柳是古典名著《水浒传》中的一个故事情节。鲁智深为了收服一众泼皮，用左手向下搂住树干，右手把住树的上半截，腰往上一挺，竟将杨柳树连根拔起。\n",
      "\n",
      "林黛玉和垂杨柳之间并没有任何联系。\n"
     ]
    }
   ],
   "source": [
    "text = '你知道林黛玉倒拔垂杨柳这个典故吗？请你给出是，否的答案，并一步一步的详细说说。'\n",
    "\n",
    "\n",
    "ans,his = chat(model_new,text,\n",
    "               his=[],temperature=0.01)\n",
    "print(ans)\n",
    "print('======================')\n",
    "ans,his = chat(model_new,text,\n",
    "               his=[],temperature=0.5)\n",
    "print(ans)\n",
    "print('======================')\n",
    "ans,his = chat(model_new,text,\n",
    "               his=[],temperature=0.8)\n",
    "print(ans)\n",
    "print('======================')\n",
    "ans,his = chat(model_new,text,\n",
    "               his=[],temperature=1)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "林黛玉是中国古典名著《红楼梦》中的女主角，她聪明伶俐、多愁善感，由于家族兴衰和身世遭遇等原因，最终抑郁而终。\n",
      "\n",
      "倒拔垂杨柳是古典名著《水浒传》的故事情节。《花和尚倒拔垂杨柳》选自于《水浒传》第七回《花和尚倒拔垂杨柳 豹子头误入白虎堂》。\n",
      "\n",
      "故事讲述了鲁智深为了收服一众泼皮，用左手向下搂住树干，右手把住树的上半截，腰往上一挺，竟将杨柳树连根拔起。\n",
      "\n",
      "鲁智深原本是渭州经略府的提辖，因打抱不平三拳打死恶霸镇关西，为了躲避官府的缉捕，他出家做了和尚，法名智深。后加入梁山泊，艺名花和尚。\n",
      "\n",
      "倒拔垂杨柳这个故事取材于《水浒传》，讲述了鲁智深为了收服一众泼皮，用左手向下搂住树干，右手把住树的上半截，腰往上一挺，竟将杨柳树连根拔起。\n",
      "\n",
      "因为鲁智深（鲁达）身高体壮，腰粗力大，所以很容易让人们想象他能够倒拔垂杨柳。\n"
     ]
    }
   ],
   "source": [
    "ans,his = chat(model_new,'你知道林黛玉倒拔垂杨柳这个典故吗？请详细说说，请一步一步的回答。',\n",
    "               his=[],temperature=0.5)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 进行否定的疑问来使用模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "是的，我知道这个典故。\n",
      "\n",
      "林黛玉是中国古典名著《红楼梦》中的主要人物，也是贾宝玉的姑表妹、恋人、知己。她的性格敏感脆弱，经常感到心力交瘁。\n",
      "\n",
      "垂杨柳是古代神话中的一个故事，讲的是一个杨柳树精变成一个青年男子，与林黛玉相爱并最终牺牲的故事。\n",
      "\n",
      "林黛玉和垂杨柳之间没有直接的联系。但是，林黛玉在《红楼梦》中的形象和性格，以及她所处的时代背景，与古代神话中的垂杨柳有一定的相似之处。例如，林黛玉的家族背景与古代贵族家族相似，她的性格也类似于垂杨柳精的牺牲精神。\n"
     ]
    }
   ],
   "source": [
    "text = '你知道林黛玉倒拔垂杨柳这个典故吗？请你给出是，否的答案，并一步一步的详细说说。'\n",
    "ans,his = chat(model_new,text,\n",
    "               his=[],temperature=0.01)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我刚才的回答有误。\n",
      "\n",
      "“林黛玉倒拔垂杨柳”是错误的故事。\n",
      "\n",
      "林黛玉是中国古典名著《红楼梦》中的主要人物，也是贾宝玉的姑表妹、恋人、知己。她的性格敏感脆弱，经常感到心力交瘁。\n",
      "\n",
      "垂杨柳是古代神话中的一个故事，讲的是一个杨柳树精变成一个青年男子，与林黛玉相爱并最终牺牲的故事。\n",
      "\n",
      "林黛玉和垂杨柳之间没有直接的联系。\n"
     ]
    }
   ],
   "source": [
    "text = '你确定你刚刚说的对吗？'\n",
    "ans,his = chat(model_new,text,\n",
    "               his=his,temperature=0.01)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatglm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
